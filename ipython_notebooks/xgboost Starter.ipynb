{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./dataset/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe have 4 categorical features in our data\\ndisplay_address\\nmanager_id\\nbuilding_id\\nlisting_id\\nSo let us label encode these features.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We have 4 categorical features in our data\n",
    "display_address\n",
    "manager_id\n",
    "building_id\n",
    "listing_id\n",
    "So let us label encode these features.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                                                         \n",
      "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "100007                               Hardwood_Floors No_Fee\n",
      "100013                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'num_photos', 'num_features', 'num_description_words', 'created_year', 'created_month', 'created_day', 'listing_id', 'created_hour', 'display_address', 'manager_id', 'building_id', 'street_address']\n"
     ]
    }
   ],
   "source": [
    "print (features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 217) (74659, 217)\n"
     ]
    }
   ],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49352x217 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1093045 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.03157\ttest-mlogloss:1.03565\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:0.975183\ttest-mlogloss:0.984093\n",
      "[2]\ttrain-mlogloss:0.922625\ttest-mlogloss:0.936861\n",
      "[3]\ttrain-mlogloss:0.880676\ttest-mlogloss:0.897858\n",
      "[4]\ttrain-mlogloss:0.843527\ttest-mlogloss:0.864483\n",
      "[5]\ttrain-mlogloss:0.809863\ttest-mlogloss:0.83526\n",
      "[6]\ttrain-mlogloss:0.783017\ttest-mlogloss:0.810685\n",
      "[7]\ttrain-mlogloss:0.754462\ttest-mlogloss:0.785698\n",
      "[8]\ttrain-mlogloss:0.728299\ttest-mlogloss:0.763341\n",
      "[9]\ttrain-mlogloss:0.705728\ttest-mlogloss:0.744387\n",
      "[10]\ttrain-mlogloss:0.684941\ttest-mlogloss:0.726963\n",
      "[11]\ttrain-mlogloss:0.669518\ttest-mlogloss:0.713679\n",
      "[12]\ttrain-mlogloss:0.653793\ttest-mlogloss:0.701128\n",
      "[13]\ttrain-mlogloss:0.63711\ttest-mlogloss:0.688288\n",
      "[14]\ttrain-mlogloss:0.625217\ttest-mlogloss:0.679101\n",
      "[15]\ttrain-mlogloss:0.611557\ttest-mlogloss:0.668418\n",
      "[16]\ttrain-mlogloss:0.600218\ttest-mlogloss:0.659369\n",
      "[17]\ttrain-mlogloss:0.589131\ttest-mlogloss:0.651533\n",
      "[18]\ttrain-mlogloss:0.577834\ttest-mlogloss:0.643161\n",
      "[19]\ttrain-mlogloss:0.566977\ttest-mlogloss:0.635822\n",
      "[20]\ttrain-mlogloss:0.55879\ttest-mlogloss:0.630396\n",
      "[21]\ttrain-mlogloss:0.551434\ttest-mlogloss:0.625846\n",
      "[22]\ttrain-mlogloss:0.545275\ttest-mlogloss:0.621628\n",
      "[23]\ttrain-mlogloss:0.536582\ttest-mlogloss:0.616314\n",
      "[24]\ttrain-mlogloss:0.530308\ttest-mlogloss:0.612485\n",
      "[25]\ttrain-mlogloss:0.524422\ttest-mlogloss:0.60898\n",
      "[26]\ttrain-mlogloss:0.517139\ttest-mlogloss:0.604933\n",
      "[27]\ttrain-mlogloss:0.511712\ttest-mlogloss:0.601792\n",
      "[28]\ttrain-mlogloss:0.506708\ttest-mlogloss:0.599043\n",
      "[29]\ttrain-mlogloss:0.501841\ttest-mlogloss:0.596346\n",
      "[30]\ttrain-mlogloss:0.49627\ttest-mlogloss:0.593937\n",
      "[31]\ttrain-mlogloss:0.492466\ttest-mlogloss:0.592133\n",
      "[32]\ttrain-mlogloss:0.48709\ttest-mlogloss:0.589427\n",
      "[33]\ttrain-mlogloss:0.481937\ttest-mlogloss:0.587201\n",
      "[34]\ttrain-mlogloss:0.477848\ttest-mlogloss:0.5855\n",
      "[35]\ttrain-mlogloss:0.473485\ttest-mlogloss:0.583465\n",
      "[36]\ttrain-mlogloss:0.468513\ttest-mlogloss:0.581271\n",
      "[37]\ttrain-mlogloss:0.46308\ttest-mlogloss:0.579274\n",
      "[38]\ttrain-mlogloss:0.458383\ttest-mlogloss:0.577299\n",
      "[39]\ttrain-mlogloss:0.453455\ttest-mlogloss:0.575175\n",
      "[40]\ttrain-mlogloss:0.449669\ttest-mlogloss:0.573681\n",
      "[41]\ttrain-mlogloss:0.4458\ttest-mlogloss:0.572063\n",
      "[42]\ttrain-mlogloss:0.441242\ttest-mlogloss:0.570543\n",
      "[43]\ttrain-mlogloss:0.438953\ttest-mlogloss:0.569861\n",
      "[44]\ttrain-mlogloss:0.436233\ttest-mlogloss:0.568713\n",
      "[45]\ttrain-mlogloss:0.4335\ttest-mlogloss:0.567711\n",
      "[46]\ttrain-mlogloss:0.430181\ttest-mlogloss:0.56667\n",
      "[47]\ttrain-mlogloss:0.428196\ttest-mlogloss:0.565777\n",
      "[48]\ttrain-mlogloss:0.425627\ttest-mlogloss:0.564745\n",
      "[49]\ttrain-mlogloss:0.421933\ttest-mlogloss:0.563711\n",
      "[50]\ttrain-mlogloss:0.417692\ttest-mlogloss:0.562565\n",
      "[51]\ttrain-mlogloss:0.415353\ttest-mlogloss:0.561686\n",
      "[52]\ttrain-mlogloss:0.412443\ttest-mlogloss:0.561059\n",
      "[53]\ttrain-mlogloss:0.409348\ttest-mlogloss:0.560346\n",
      "[54]\ttrain-mlogloss:0.40623\ttest-mlogloss:0.559724\n",
      "[55]\ttrain-mlogloss:0.403834\ttest-mlogloss:0.55938\n",
      "[56]\ttrain-mlogloss:0.401961\ttest-mlogloss:0.558907\n",
      "[57]\ttrain-mlogloss:0.398298\ttest-mlogloss:0.558132\n",
      "[58]\ttrain-mlogloss:0.396286\ttest-mlogloss:0.557596\n",
      "[59]\ttrain-mlogloss:0.39366\ttest-mlogloss:0.557169\n",
      "[60]\ttrain-mlogloss:0.39056\ttest-mlogloss:0.556483\n",
      "[61]\ttrain-mlogloss:0.38872\ttest-mlogloss:0.556377\n",
      "[62]\ttrain-mlogloss:0.386326\ttest-mlogloss:0.555719\n",
      "[63]\ttrain-mlogloss:0.383123\ttest-mlogloss:0.555056\n",
      "[64]\ttrain-mlogloss:0.381083\ttest-mlogloss:0.554718\n",
      "[65]\ttrain-mlogloss:0.378911\ttest-mlogloss:0.554284\n",
      "[66]\ttrain-mlogloss:0.375777\ttest-mlogloss:0.554031\n",
      "[67]\ttrain-mlogloss:0.373323\ttest-mlogloss:0.554127\n",
      "[68]\ttrain-mlogloss:0.371373\ttest-mlogloss:0.553856\n",
      "[69]\ttrain-mlogloss:0.369145\ttest-mlogloss:0.553493\n",
      "[70]\ttrain-mlogloss:0.366829\ttest-mlogloss:0.552851\n",
      "[71]\ttrain-mlogloss:0.364959\ttest-mlogloss:0.552366\n",
      "[72]\ttrain-mlogloss:0.363047\ttest-mlogloss:0.551747\n",
      "[73]\ttrain-mlogloss:0.360373\ttest-mlogloss:0.551715\n",
      "[74]\ttrain-mlogloss:0.357683\ttest-mlogloss:0.551609\n",
      "[75]\ttrain-mlogloss:0.356243\ttest-mlogloss:0.55137\n",
      "[76]\ttrain-mlogloss:0.353847\ttest-mlogloss:0.551192\n",
      "[77]\ttrain-mlogloss:0.351091\ttest-mlogloss:0.550995\n",
      "[78]\ttrain-mlogloss:0.348551\ttest-mlogloss:0.550416\n",
      "[79]\ttrain-mlogloss:0.34653\ttest-mlogloss:0.550205\n",
      "[80]\ttrain-mlogloss:0.344613\ttest-mlogloss:0.549825\n",
      "[81]\ttrain-mlogloss:0.342698\ttest-mlogloss:0.549624\n",
      "[82]\ttrain-mlogloss:0.339992\ttest-mlogloss:0.549325\n",
      "[83]\ttrain-mlogloss:0.338461\ttest-mlogloss:0.549037\n",
      "[84]\ttrain-mlogloss:0.336836\ttest-mlogloss:0.548803\n",
      "[85]\ttrain-mlogloss:0.33469\ttest-mlogloss:0.548534\n",
      "[86]\ttrain-mlogloss:0.333471\ttest-mlogloss:0.548329\n",
      "[87]\ttrain-mlogloss:0.331887\ttest-mlogloss:0.548242\n",
      "[88]\ttrain-mlogloss:0.330838\ttest-mlogloss:0.548158\n",
      "[89]\ttrain-mlogloss:0.328357\ttest-mlogloss:0.548348\n",
      "[90]\ttrain-mlogloss:0.32624\ttest-mlogloss:0.54824\n",
      "[91]\ttrain-mlogloss:0.324287\ttest-mlogloss:0.548205\n",
      "[92]\ttrain-mlogloss:0.322305\ttest-mlogloss:0.548008\n",
      "[93]\ttrain-mlogloss:0.320402\ttest-mlogloss:0.547645\n",
      "[94]\ttrain-mlogloss:0.318685\ttest-mlogloss:0.547672\n",
      "[95]\ttrain-mlogloss:0.316675\ttest-mlogloss:0.547316\n",
      "[96]\ttrain-mlogloss:0.314515\ttest-mlogloss:0.546811\n",
      "[97]\ttrain-mlogloss:0.312883\ttest-mlogloss:0.5469\n",
      "[98]\ttrain-mlogloss:0.310715\ttest-mlogloss:0.546816\n",
      "[99]\ttrain-mlogloss:0.309188\ttest-mlogloss:0.546594\n",
      "[100]\ttrain-mlogloss:0.306812\ttest-mlogloss:0.546763\n",
      "[101]\ttrain-mlogloss:0.305386\ttest-mlogloss:0.546501\n",
      "[102]\ttrain-mlogloss:0.303254\ttest-mlogloss:0.546476\n",
      "[103]\ttrain-mlogloss:0.302107\ttest-mlogloss:0.546543\n",
      "[104]\ttrain-mlogloss:0.300633\ttest-mlogloss:0.546539\n",
      "[105]\ttrain-mlogloss:0.298595\ttest-mlogloss:0.54653\n",
      "[106]\ttrain-mlogloss:0.297444\ttest-mlogloss:0.546522\n",
      "[107]\ttrain-mlogloss:0.296242\ttest-mlogloss:0.54631\n",
      "[108]\ttrain-mlogloss:0.294874\ttest-mlogloss:0.546179\n",
      "[109]\ttrain-mlogloss:0.292491\ttest-mlogloss:0.546589\n",
      "[110]\ttrain-mlogloss:0.291482\ttest-mlogloss:0.546419\n",
      "[111]\ttrain-mlogloss:0.289916\ttest-mlogloss:0.546306\n",
      "[112]\ttrain-mlogloss:0.288079\ttest-mlogloss:0.546707\n",
      "[113]\ttrain-mlogloss:0.286719\ttest-mlogloss:0.546904\n",
      "[114]\ttrain-mlogloss:0.284317\ttest-mlogloss:0.546932\n",
      "[115]\ttrain-mlogloss:0.282902\ttest-mlogloss:0.547047\n",
      "[116]\ttrain-mlogloss:0.280923\ttest-mlogloss:0.547126\n",
      "[117]\ttrain-mlogloss:0.279459\ttest-mlogloss:0.547268\n",
      "[118]\ttrain-mlogloss:0.277631\ttest-mlogloss:0.547453\n",
      "[119]\ttrain-mlogloss:0.275934\ttest-mlogloss:0.547292\n",
      "[120]\ttrain-mlogloss:0.275088\ttest-mlogloss:0.547318\n",
      "[121]\ttrain-mlogloss:0.273732\ttest-mlogloss:0.547413\n",
      "[122]\ttrain-mlogloss:0.27287\ttest-mlogloss:0.54732\n",
      "[123]\ttrain-mlogloss:0.271787\ttest-mlogloss:0.547334\n",
      "[124]\ttrain-mlogloss:0.270132\ttest-mlogloss:0.547417\n",
      "[125]\ttrain-mlogloss:0.268978\ttest-mlogloss:0.547281\n",
      "[126]\ttrain-mlogloss:0.267693\ttest-mlogloss:0.547431\n",
      "[127]\ttrain-mlogloss:0.267066\ttest-mlogloss:0.547526\n",
      "[128]\ttrain-mlogloss:0.266246\ttest-mlogloss:0.54748\n",
      "Stopping. Best iteration:\n",
      "[108]\ttrain-mlogloss:0.294874\ttest-mlogloss:0.546179\n",
      "\n",
      "[0.54747995652678072]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-46e997a98dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"high\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"low\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"listing_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisting_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xgb_starter2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-19fbdb114799>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddartha/git/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddartha/git/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddartha/git/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=400)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_starter2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
